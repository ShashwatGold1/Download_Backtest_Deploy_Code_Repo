{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f27fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from bisect import bisect_right\n",
    "import functions as f\n",
    "import winsound\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "def shift_time(timestamp_str, minutes=0, seconds=0, hours=0):\n",
    "    # Only time (HH:MM:SS)\n",
    "    if len(timestamp_str) == 8:\n",
    "        h = int(timestamp_str[0:2])\n",
    "        m = int(timestamp_str[3:5])\n",
    "        s = int(timestamp_str[6:8])\n",
    "        total = h * 3600 + m * 60 + s + hours * 3600 + minutes * 60 + seconds\n",
    "        total %= 86400  # Wrap around 24h\n",
    "        return f\"{total // 3600:02}:{(total % 3600) // 60:02}:{total % 60:02}\"\n",
    "\n",
    "    # Only date (YYYY-MM-DD)\n",
    "    elif len(timestamp_str) == 10:\n",
    "        y, mo, d = map(int, timestamp_str.split(\"-\"))\n",
    "        t = timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "        dt = datetime(y, mo, d) + t\n",
    "        return dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Full datetime (YYYY-MM-DD HH:MM:SS)\n",
    "    else:\n",
    "        y = int(timestamp_str[0:4])\n",
    "        mo = int(timestamp_str[5:7])\n",
    "        d = int(timestamp_str[8:10])\n",
    "        h = int(timestamp_str[11:13])\n",
    "        m = int(timestamp_str[14:16])\n",
    "        s = int(timestamp_str[17:19])\n",
    "        total = (datetime(y, mo, d, h, m, s) +\n",
    "                 timedelta(hours=hours, minutes=minutes, seconds=seconds))\n",
    "        return total.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14167045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already converted to parquet format\n",
      "All files already converted to parquet format\n",
      "All files already converted to parquet format\n",
      "Processing File: 2025_01_01.parquet\n",
      "Current Date: 2025-01-01\n",
      "Processing File: 2025_01_02.parquet\n",
      "Current Date: 2025-01-02\n",
      "Processing File: 2025_01_03.parquet\n",
      "Current Date: 2025-01-03\n",
      "Processing File: 2025_01_06.parquet\n",
      "Current Date: 2025-01-06\n",
      "Processing File: 2025_01_07.parquet\n",
      "Current Date: 2025-01-07\n",
      "Processing File: 2025_01_08.parquet\n",
      "Current Date: 2025-01-08\n",
      "Processing File: 2025_01_09.parquet\n",
      "Current Date: 2025-01-09\n",
      "Processing File: 2025_01_10.parquet\n",
      "Current Date: 2025-01-10\n",
      "Processing File: 2025_01_13.parquet\n",
      "Current Date: 2025-01-13\n",
      "Processing File: 2025_01_14.parquet\n",
      "Current Date: 2025-01-14\n",
      "Processing File: 2025_01_15.parquet\n",
      "Current Date: 2025-01-15\n",
      "Processing File: 2025_01_16.parquet\n",
      "Current Date: 2025-01-16\n",
      "Processing File: 2025_01_17.parquet\n",
      "Current Date: 2025-01-17\n",
      "Processing File: 2025_01_20.parquet\n",
      "Current Date: 2025-01-20\n",
      "Processing File: 2025_01_21.parquet\n",
      "Current Date: 2025-01-21\n",
      "Processing File: 2025_01_22.parquet\n",
      "Current Date: 2025-01-22\n",
      "Processing File: 2025_01_23.parquet\n",
      "Current Date: 2025-01-23\n",
      "Processing File: 2025_01_24.parquet\n",
      "Current Date: 2025-01-24\n",
      "Processing File: 2025_01_27.parquet\n",
      "Current Date: 2025-01-27\n",
      "Processing File: 2025_01_28.parquet\n",
      "Current Date: 2025-01-28\n",
      "Processing File: 2025_01_29.parquet\n",
      "Current Date: 2025-01-29\n",
      "Processing File: 2025_01_30.parquet\n",
      "Current Date: 2025-01-30\n",
      "Processing File: 2025_01_31.parquet\n",
      "Current Date: 2025-01-31\n",
      "Processing File: 2025_02_03.parquet\n",
      "Current Date: 2025-02-03\n",
      "Processing File: 2025_02_04.parquet\n",
      "Current Date: 2025-02-04\n",
      "Processing File: 2025_02_05.parquet\n",
      "Current Date: 2025-02-05\n",
      "Processing File: 2025_02_06.parquet\n",
      "Current Date: 2025-02-06\n",
      "Processing File: 2025_02_07.parquet\n",
      "Current Date: 2025-02-07\n",
      "Processing File: 2025_02_10.parquet\n",
      "Current Date: 2025-02-10\n",
      "Processing File: 2025_02_11.parquet\n",
      "Current Date: 2025-02-11\n",
      "Processing File: 2025_02_12.parquet\n",
      "Current Date: 2025-02-12\n",
      "Processing File: 2025_02_13.parquet\n",
      "Current Date: 2025-02-13\n",
      "Processing File: 2025_02_14.parquet\n",
      "Current Date: 2025-02-14\n",
      "Processing File: 2025_02_17.parquet\n",
      "Current Date: 2025-02-17\n",
      "Processing File: 2025_02_18.parquet\n",
      "Current Date: 2025-02-18\n",
      "Processing File: 2025_02_19.parquet\n",
      "Current Date: 2025-02-19\n",
      "Processing File: 2025_02_20.parquet\n",
      "Current Date: 2025-02-20\n",
      "Processing File: 2025_02_21.parquet\n",
      "Current Date: 2025-02-21\n",
      "Processing File: 2025_02_24.parquet\n",
      "Current Date: 2025-02-24\n",
      "Processing File: 2025_02_25.parquet\n",
      "Current Date: 2025-02-25\n",
      "Processing File: 2025_02_27.parquet\n",
      "Current Date: 2025-02-27\n",
      "Processing File: 2025_02_28.parquet\n",
      "Current Date: 2025-02-28\n",
      "Processing File: 2025_03_03.parquet\n",
      "Current Date: 2025-03-03\n",
      "Processing File: 2025_03_04.parquet\n",
      "Current Date: 2025-03-04\n",
      "Processing File: 2025_03_05.parquet\n",
      "Current Date: 2025-03-05\n",
      "Processing File: 2025_03_06.parquet\n",
      "Current Date: 2025-03-06\n",
      "Processing File: 2025_03_07.parquet\n",
      "Current Date: 2025-03-07\n",
      "Processing File: 2025_03_10.parquet\n",
      "Current Date: 2025-03-10\n",
      "Processing File: 2025_03_11.parquet\n",
      "Current Date: 2025-03-11\n",
      "Processing File: 2025_03_12.parquet\n",
      "Current Date: 2025-03-12\n",
      "Processing File: 2025_03_13.parquet\n",
      "Current Date: 2025-03-13\n",
      "Processing File: 2025_03_17.parquet\n",
      "Current Date: 2025-03-17\n",
      "Processing File: 2025_03_18.parquet\n",
      "Current Date: 2025-03-18\n",
      "Processing File: 2025_03_19.parquet\n",
      "Current Date: 2025-03-19\n",
      "Processing File: 2025_03_20.parquet\n",
      "Current Date: 2025-03-20\n",
      "Processing File: 2025_03_21.parquet\n",
      "Current Date: 2025-03-21\n",
      "Processing File: 2025_03_24.parquet\n",
      "Current Date: 2025-03-24\n",
      "Processing File: 2025_03_25.parquet\n",
      "Current Date: 2025-03-25\n",
      "Processing File: 2025_03_26.parquet\n",
      "Current Date: 2025-03-26\n",
      "Processing File: 2025_03_27.parquet\n",
      "Current Date: 2025-03-27\n",
      "Processing File: 2025_03_28.parquet\n",
      "Current Date: 2025-03-28\n",
      "Processing File: 2025_04_01.parquet\n",
      "Current Date: 2025-04-01\n",
      "Processing File: 2025_04_02.parquet\n",
      "Current Date: 2025-04-02\n",
      "Processing File: 2025_04_03.parquet\n",
      "Current Date: 2025-04-03\n",
      "Processing File: 2025_04_04.parquet\n",
      "Current Date: 2025-04-04\n",
      "Processing File: 2025_04_07.parquet\n",
      "Current Date: 2025-04-07\n",
      "Processing File: 2025_04_08.parquet\n",
      "Current Date: 2025-04-08\n",
      "Processing File: 2025_04_09.parquet\n",
      "Current Date: 2025-04-09\n",
      "Processing File: 2025_04_11.parquet\n",
      "Current Date: 2025-04-11\n"
     ]
    }
   ],
   "source": [
    "def calculate_candle_gains(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df.copy()  # Avoid modifying the original DataFrame\n",
    "    df['STD_gain'] = round(df['STD'].pct_change() * 100, 2)\n",
    "    df['Middle_gain'] = round(df['Middle'].pct_change() * 100, 2)\n",
    "\n",
    "    return df\n",
    "\n",
    "TIME_RANGE_SORTED_1T = pd.date_range(start='09:15:00', end='15:30:00', freq='5s').strftime('%H:%M:%S').tolist()\n",
    "\n",
    "def get_resume_index(df, while_time):\n",
    "    idx = np.searchsorted(TIME_RANGE_SORTED_1T, while_time, side='right') - 1\n",
    "\n",
    "    # Early exit if while_time is beyond last possible time\n",
    "    if idx >= len(TIME_RANGE_SORTED_1T):\n",
    "        return None\n",
    "\n",
    "    rounded_arr = df['time'].values\n",
    "\n",
    "    # Loop until a matching time is found in df\n",
    "    while idx < len(TIME_RANGE_SORTED_1T):\n",
    "        next_time = TIME_RANGE_SORTED_1T[idx]\n",
    "        match_idx = np.flatnonzero(rounded_arr == next_time)\n",
    "\n",
    "        if match_idx.size > 0:\n",
    "            return match_idx[0] - len(df)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    return None  # No future matching time found\n",
    "\n",
    "results_ddff = []\n",
    "\n",
    "# === Paths ===\n",
    "sym_df_folder_path = r'D:\\Offline Data\\Processed Data\\Get_symbol'\n",
    "sym_df_folder_path = f.convert_csv_to_parquet(sym_df_folder_path)\n",
    "\n",
    "folder_path = r'D:\\Offline Data\\Processed Data\\Nifty_5_Second_ICICI\\Nifty_5_Second_with_indicator_ICICI'\n",
    "folder_path = f.convert_csv_to_parquet(folder_path)\n",
    "\n",
    "su_1m_folder_path = r'D:\\Offline Data\\Processed Data\\Nifty_1_Minute_ICICI\\Nifty_1_Minute_with_indicator_ICICI'\n",
    "su_1m_folder_path = f.convert_csv_to_parquet(su_1m_folder_path)\n",
    "\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "# === Loop through files ===\n",
    "for n in range(0, len(csv_files)):\n",
    "\n",
    "    print(f\"Processing File: {csv_files[n]}\")\n",
    "\n",
    "    current_date = csv_files[n].replace('.parquet', '').replace('_', '-')\n",
    "    print(f\"Current Date: {current_date}\")\n",
    "\n",
    "    # ===== 5 Second df Main =====\n",
    "    file_path = os.path.join(folder_path, csv_files[n])\n",
    "    _5s_df = pd.read_parquet(file_path)\n",
    "    _5s_df = calculate_candle_gains(_5s_df)\n",
    "    _5s_df['time'] = _5s_df['datetime'].str[-8:-2] + '00'\n",
    "    _5s_symbol_groups = {k: v.reset_index(drop=True) for k, v in _5s_df.groupby('symbol')}    # Precompute Lookup\n",
    "\n",
    "    # ===== 1 Minute supporting df =====\n",
    "    su_1m_file_path = os.path.join(su_1m_folder_path, csv_files[n])\n",
    "    _su_1m_df = pd.read_parquet(su_1m_file_path)\n",
    "    su_1m_symbol_groups = {k: v.reset_index(drop=True) for k, v in _su_1m_df.groupby('symbol')}    # Precompute Lookup\n",
    "\n",
    "    # ===== Find symbol =====\n",
    "    sym_file_path = os.path.join(sym_df_folder_path, csv_files[n])\n",
    "    sym_df = pd.read_parquet(sym_file_path)\n",
    "    time_to_symbol = dict(zip(sym_df['time'], sym_df['symbol']))    # Precompute Lookup\n",
    "\n",
    "    # -----------------------------\n",
    "\n",
    "    while_time = \"09:15:00\"\n",
    "\n",
    "    entry_i = None                  # Backtesting\n",
    "\n",
    "    symbol_change_Flag = False   \n",
    "    symbol_change_Flag_symbol = None\n",
    "\n",
    "    while True:\n",
    "        current_symbol = symbol_change_Flag_symbol if symbol_change_Flag else time_to_symbol.get(while_time)\n",
    "        # print(current_symbol, symbol_change_Flag_symbol, symbol_change_Flag, time_to_symbol.get(while_time), while_time)\n",
    "        symbol_change_Flag = False   \n",
    "\n",
    "        df = _5s_symbol_groups.get(current_symbol)\n",
    "        length_df = -len(df)\n",
    "        # print(length_df)\n",
    "\n",
    "        su_1m_df = su_1m_symbol_groups.get(current_symbol)\n",
    "        su_1m_dict = dict(zip(su_1m_df['datetime'].values, su_1m_df.to_dict('records')))\n",
    "        keys = list(su_1m_dict.keys())\n",
    "        length_su_1m_df = len(su_1m_df)\n",
    "\n",
    "        datetime_arr = df['datetime'].values\n",
    "        symbol_arr = df['symbol'].values\n",
    "        open_arr = df['open'].values\n",
    "        high_arr = df['high'].values\n",
    "        low_arr = df['low'].values\n",
    "        close_arr = df['close'].values\n",
    "        open_interest_arr = df['open_interest'].values\n",
    "        volume_arr = df['volume'].values\n",
    "        STD_arr = df['STD'].values\n",
    "        Middle_arr = df['Middle'].values\n",
    "        Upper_arr = df['Upper'].values\n",
    "        Lower_arr = df['Lower'].values\n",
    "        pctB_arr = df['%B'].values\n",
    "        STD_gain_arr = df['STD_gain'].values\n",
    "        Middle_gain_arr = df['Middle_gain'].values\n",
    "        time_arr = df['time'].values\n",
    "\n",
    "        resume_index = get_resume_index(df, while_time) if while_time != \"09:15:00\" else -len(df)\n",
    "\n",
    "        entry_signal_is = False             # Backtesting\n",
    "        # print(\"a\", while_time, \"--------------------------------------\")\n",
    "\n",
    "        for i in range(resume_index, 0):\n",
    "            # print(\"i am hear 001\")\n",
    "            # print(datetime_arr[i])\n",
    "            while_time = datetime_arr[i][-8:] \n",
    "\n",
    "            if symbol_change_Flag and not entry_signal_is:\n",
    "                break\n",
    "\n",
    "            next_symbol = time_to_symbol.get(shift_time(while_time, minutes=-1))\n",
    "\n",
    "            if next_symbol != symbol_arr[i] and next_symbol is not None:\n",
    "                if not entry_signal_is:\n",
    "                    # print(\"Symbol Change\", symbol_arr[i], next_symbol)\n",
    "                    symbol_change_Flag_symbol = next_symbol\n",
    "                    symbol_change_Flag = True\n",
    "                    break\n",
    "                else:\n",
    "                    symbol_change_Flag_symbol = next_symbol\n",
    "                    symbol_change_Flag = True\n",
    "\n",
    "            target_time = datetime_arr[i][:-2] + '00'\n",
    "\n",
    "            if target_time[-8:] > \"09:17:00\":\n",
    "                idx_1m = keys.index(target_time) - length_su_1m_df\n",
    "\n",
    "                # row = su_1m_dict[keys[idx_1m]] # it's have look ahead bias\n",
    "                prev_row_1 = su_1m_dict[keys[idx_1m - 1]]\n",
    "                prev_row_2 = su_1m_dict[keys[idx_1m - 2]]\n",
    "                prev_row_3 = su_1m_dict[keys[idx_1m - 3]]\n",
    "                # print(datetime_arr[i])\n",
    "\n",
    "                # ==========================================\n",
    "                # ==========================================\n",
    "                # Backtesting model\n",
    "\n",
    "                entry_signal_is = True\n",
    "\n",
    "                # print(\"---- Entry ----\", symbol_arr[i][-5:])\n",
    "                # print(datetime_arr[i])\n",
    "\n",
    "                entry_i = i\n",
    "\n",
    "                # main_df model\n",
    "                entry_datetime = datetime_arr[i]\n",
    "                entry_symbol = symbol_arr[i]\n",
    "                entry_open = open_arr[i]\n",
    "                entry_high = high_arr[i]\n",
    "                entry_low = low_arr[i]\n",
    "                entry_close = close_arr[i]\n",
    "                entry_open_interest = open_interest_arr[i]\n",
    "                entry_volume = volume_arr[i]\n",
    "                entry_STD = STD_arr[i]\n",
    "                entry_Middle = Middle_arr[i]\n",
    "                entry_Upper = Upper_arr[i]\n",
    "                entry_Lower = Lower_arr[i]\n",
    "                entry_pctB = pctB_arr[i]\n",
    "\n",
    "                # =====================================================\n",
    "\n",
    "                sl_1 = close_arr[entry_i] * 0.99\n",
    "                sl_2 = close_arr[entry_i] * 0.985\n",
    "                sl_3 = close_arr[entry_i] * 0.98\n",
    "\n",
    "                tp_1 = close_arr[entry_i] * 1.10\n",
    "                tp_2 = close_arr[entry_i] * 1.25\n",
    "                tp_3 = close_arr[entry_i] * 1.50\n",
    "\n",
    "                allex = 6       # how many exit\n",
    "                allex_n = 0\n",
    "\n",
    "                exit_sl1, exit_sl1_index, exit_sl1_time = None, 0, None\n",
    "                exit_sl2, exit_sl2_index, exit_sl2_time = None, 0, None\n",
    "                exit_sl3, exit_sl3_index, exit_sl3_time = None, 0, None\n",
    "\n",
    "                exit_tp1, exit_tp1_index, exit_tp1_time = None, 0, None\n",
    "                exit_tp2, exit_tp2_index, exit_tp2_time = None, 0, None\n",
    "                exit_tp3, exit_tp3_index, exit_tp3_time = None, 0, None\n",
    "\n",
    "                # print(i, \"--------------------------------\")\n",
    "\n",
    "                next_symbol = time_to_symbol.get(shift_time(while_time, minutes=-1))\n",
    "\n",
    "                if next_symbol != symbol_arr[i] and next_symbol is not None:\n",
    "                    winsound.PlaySound(\"alarm.wav\", winsound.SND_FILENAME | winsound.SND_ASYNC)\n",
    "                    print(\"\\033[1;31mSymbol error\\033[0m\")\n",
    "                    raise Exception(\"\\033[1;31mSymbol error\\033[0m\")\n",
    "\n",
    "                for j in range(i+1, 0):\n",
    "\n",
    "                    # ----- stoploss_1  \n",
    "                    # =====================================================\n",
    "                    if (low_arr[j] < sl_1 or j == -1) and exit_sl1 is None:\n",
    "                        # print(\"---- stoploss_1 ----\")\n",
    "                        exit_sl1 = (close_arr[j] if j == -1 else sl_1) * 0.9975     # Charging 0.25% brokerage\n",
    "                        exit_sl1_time = datetime_arr[j]\n",
    "                        exit_sl1_index = j\n",
    "                        allex_n += 1\n",
    "\n",
    "                    # ----- stoploss_2  \n",
    "                    # =====================================================\n",
    "                    if (low_arr[j] < sl_2 or j == -1) and exit_sl2 is None:\n",
    "                        # print(\"---- stoploss_2 ----\")\n",
    "                        exit_sl2 = (close_arr[j] if j == -1 else sl_2) * 0.9975     # Charging 0.25% brokerage\n",
    "                        exit_sl2_time = datetime_arr[j]\n",
    "                        exit_sl2_index = j\n",
    "                        allex_n += 1\n",
    "\n",
    "                    # ----- stoploss_3  \n",
    "                    # =====================================================\n",
    "                    if (low_arr[j] < sl_3 or j == -1) and exit_sl3 is None:\n",
    "                        # print(\"---- stoploss_3 ----\")\n",
    "                        exit_sl3 = (close_arr[j] if j == -1 else sl_3) * 0.9975     # Charging 0.25% brokerage\n",
    "                        exit_sl3_time = datetime_arr[j]\n",
    "                        exit_sl3_index = j\n",
    "                        allex_n += 1\n",
    "\n",
    "                    # ----- target_1  \n",
    "                    # =====================================================\n",
    "                    if (high_arr[j] > tp_1 or j == -1) and exit_tp1 is None:\n",
    "                        # print(\"---- target_1 ----\")\n",
    "                        exit_tp1 = (close_arr[j] if j == -1 else tp_1) * 0.9975     # Charging 0.25% brokerage\n",
    "                        exit_tp1_time = datetime_arr[j]\n",
    "                        exit_tp1_index = j\n",
    "                        allex_n += 1\n",
    "\n",
    "                    # ----- target_2  \n",
    "                    # =====================================================\n",
    "                    if (high_arr[j] > tp_2 or j == -1) and exit_tp2 is None:\n",
    "                        # print(\"---- target_2 ----\", symbol_arr[j][-5:])\n",
    "                        exit_tp2 = (close_arr[j] if j == -1 else tp_2) * 0.9975     # Charging 0.25% brokerage\n",
    "                        exit_tp2_time = datetime_arr[j]\n",
    "                        exit_tp2_index = j\n",
    "                        allex_n += 1\n",
    "\n",
    "                    # ----- target_2  \n",
    "                    # =====================================================\n",
    "                    if (high_arr[j] > tp_3 or j == -1) and exit_tp3 is None:\n",
    "                        # print(\"---- target_3 ----\", symbol_arr[j][-5:])\n",
    "                        exit_tp3 = (close_arr[j] if j == -1 else tp_3) * 0.9975     # Charging 0.25% brokerage\n",
    "                        exit_tp3_time = datetime_arr[j]\n",
    "                        exit_tp3_index = j\n",
    "                        allex_n += 1\n",
    "\n",
    "                    if allex == allex_n:\n",
    "                        # print(allex, allex_n)\n",
    "                        # print(\"i am hear 002\")\n",
    "\n",
    "                        entry_signal_is = False\n",
    "\n",
    "                        results_ddff.append({\n",
    "                            'entry_datetime': entry_datetime,\n",
    "                            'entry_symbol': entry_symbol,\n",
    "                            'combi_entry_open': entry_open,\n",
    "                            'combi_entry_high': entry_high,\n",
    "                            'combi_entry_low': entry_low,\n",
    "                            'combi_entry_close': entry_close,\n",
    "                            'combi_entry_open_interest': entry_open_interest,\n",
    "                            'combi_entry_volume': entry_volume,\n",
    "                            'combi_entry_STD': entry_STD,\n",
    "                            'combi_entry_Middle': entry_Middle,\n",
    "                            'combi_entry_Upper': entry_Upper,\n",
    "                            'combi_entry_Lower': entry_Lower,\n",
    "                            'combi_entry_pctB': entry_pctB,\n",
    "                            'exit_sl1': exit_sl1, 'exit_sl1_pnl': round((exit_sl1 - entry_close) / entry_close * 100, 2), 'exit_sl1_index': abs(entry_i) - abs(exit_sl1_index), 'exit_sl1_time': exit_sl1_time,\n",
    "                            'exit_sl2': exit_sl2, 'exit_sl2_pnl': round((exit_sl2 - entry_close) / entry_close * 100, 2), 'exit_sl2_index': abs(entry_i) - abs(exit_sl2_index), 'exit_sl2_time': exit_sl2_time,\n",
    "                            'exit_sl3': exit_sl3, 'exit_sl3_pnl': round((exit_sl3 - entry_close) / entry_close * 100, 2), 'exit_sl3_index': abs(entry_i) - abs(exit_sl3_index), 'exit_sl3_time': exit_sl3_time,\n",
    "                            'exit_tp1': exit_tp1, 'exit_tp1_pnl': round((exit_tp1 - entry_close) / entry_close * 100, 2), 'exit_tp1_index': abs(entry_i) - abs(exit_tp1_index), 'exit_tp1_time': exit_tp1_time,\n",
    "                            'exit_tp2': exit_tp2, 'exit_tp2_pnl': round((exit_tp2 - entry_close) / entry_close * 100, 2), 'exit_tp2_index': abs(entry_i) - abs(exit_tp2_index), 'exit_tp2_time': exit_tp2_time,\n",
    "                            'exit_tp3': exit_tp3, 'exit_tp3_pnl': round((exit_tp3 - entry_close) / entry_close * 100, 2), 'exit_tp3_index': abs(entry_i) - abs(exit_tp3_index), 'exit_tp3_time': exit_tp3_time,\n",
    "                            })\n",
    "\n",
    "                        # ---------- Plotting -----------\n",
    "\n",
    "                        # # main 5 second\n",
    "                        # starting, ending = f.starting_ending(entry_i, exit_index, length_df)\n",
    "                        # df_for_plot = df[starting:ending].copy()\n",
    "\n",
    "                        # f.plot_chart(df_for_plot,\n",
    "                        #             entry_time = entry_time, exit_time = exit_time,\n",
    "                        #             entry_price = entry_price, exit_price = exit_price,\n",
    "                        #             position = \"Long\",\n",
    "                        #             pnl = pnl,\n",
    "                        #             trade_n = 0,\n",
    "                        #             supertrend_start_time = entry_time,\n",
    "                        #             plot_bollinger = True,\n",
    "                        #             plot_pctb = True,\n",
    "                        #             plot_supertrend = False,\n",
    "                        #             plot_entry_exit = True,\n",
    "                        #             save_chart = False)\n",
    "\n",
    "                        break # break loop\n",
    "                        \n",
    "                # ==========================================\n",
    "                # ==========================================\n",
    "\n",
    "        if i == -1:\n",
    "            if len(results_ddff) < 1:\n",
    "                raise ValueError(\"\\033[1;30mManual error :\\033[0m 'allex' variable is incorrect\")\n",
    "            break\n",
    "\n",
    "main_df = pd.DataFrame(results_ddff)\n",
    "\n",
    "exit_keywords = [col for col, is_true in main_df.isnull().all().items() if is_true]\n",
    "main_df = main_df.drop([col for col in main_df.columns if any(kw in col for kw in exit_keywords)],axis=1)\n",
    "\n",
    "main_df['entry_date'] = main_df['entry_datetime'].str[:-9]\n",
    "main_df['entry_time'] = main_df['entry_datetime'].str[-8:]\n",
    "main_df['is_last_candle'] = main_df['entry_date'] == main_df['entry_date'].shift(-1)\n",
    "\n",
    "os.makedirs('Data', exist_ok=True)\n",
    "main_df.to_csv('Data/backtest_model_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
