{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48edada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_resolution_seconds(resolution):\n",
    "    \"\"\"Convert resolution string to seconds\"\"\"\n",
    "    resolution_map = {\n",
    "        \"5S\": 5, \"10S\": 10, \"15S\": 15, \"30S\": 30, \"45S\": 45,\n",
    "        \"1\": 60, \"2\": 120, \"3\": 180, \"5\": 300, \"10\": 600, \n",
    "        \"15\": 900, \"20\": 1200, \"30\": 1800, \"60\": 3600, \n",
    "        \"120\": 7200, \"240\": 14400, \"D\": 22500\n",
    "    }\n",
    "    return resolution_map.get(resolution, 0)\n",
    "\n",
    "\n",
    "def fill_missing_candles(resolution, data_folder, date_range_start, date_range_end):\n",
    "    \"\"\"\n",
    "    Fill missing candles for all stocks in a resolution folder\n",
    "    - Fast vectorized approach\n",
    "    - No JSON file dependency\n",
    "    \"\"\"\n",
    "    resolution_seconds = get_resolution_seconds(resolution)\n",
    "    if resolution_seconds == 0:\n",
    "        print(f\"❌ Unknown resolution: {resolution}\")\n",
    "        return\n",
    "    \n",
    "    if resolution_seconds >= 360:\n",
    "        print(f\"❌ Resolution {resolution} >= 6 minutes. Only works for < 6 min resolutions\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{'FILLING MISSING CANDLES':^100}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"Resolution: {resolution} ({resolution_seconds}s)\")\n",
    "    print(f\"Data Folder: {data_folder}\")\n",
    "    print(f\"Date Range: {date_range_start} to {date_range_end}\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    # Get all CSV files in folder\n",
    "    csv_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "    total_stocks = len(csv_files)\n",
    "    \n",
    "    print(f\"Found {total_stocks} CSV files\\n\")\n",
    "    \n",
    "    # Track changes\n",
    "    stocks_processed = 0\n",
    "    total_candles_filled = 0\n",
    "    fill_summary = []\n",
    "    \n",
    "    for idx, csv_filename in enumerate(csv_files, 1):\n",
    "        stock_name = csv_filename.replace(f\"_Fyers_{resolution}.csv\", \"\")\n",
    "        csv_path = os.path.join(data_folder, csv_filename)\n",
    "        \n",
    "        print(f\"[{idx}/{total_stocks}] Processing {stock_name}...\", end=\" \", flush=True)\n",
    "        \n",
    "        # Read CSV\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "        original_count = len(df)\n",
    "        \n",
    "        # Get unique dates\n",
    "        df['Date'] = df['Datetime'].dt.date\n",
    "        dates = df['Date'].unique()\n",
    "        \n",
    "        filled_timestamps = []\n",
    "        new_rows = []\n",
    "        \n",
    "        for date in dates:\n",
    "            date_str = str(date)\n",
    "            day_data = df[df['Date'] == date].copy()\n",
    "            \n",
    "            # Generate expected timestamps for this day\n",
    "            market_start = pd.Timestamp(f\"{date_str} 09:15:00\")\n",
    "            market_end = pd.Timestamp(f\"{date_str} 15:29:55\")\n",
    "            \n",
    "            expected_timestamps = pd.date_range(\n",
    "                start=market_start, \n",
    "                end=market_end, \n",
    "                freq=f'{resolution_seconds}S'\n",
    "            )\n",
    "            \n",
    "            # Find missing timestamps\n",
    "            actual_timestamps = set(day_data['Datetime'])\n",
    "            missing_timestamps = [ts for ts in expected_timestamps if ts not in actual_timestamps]\n",
    "            \n",
    "            if not missing_timestamps:\n",
    "                continue\n",
    "            \n",
    "            # Get last available timestamp for this day\n",
    "            last_available_ts = day_data['Datetime'].max()\n",
    "            \n",
    "            # Create a lookup dict for faster access\n",
    "            day_data_indexed = day_data.set_index('Datetime')\n",
    "            \n",
    "            # Process missing timestamps\n",
    "            for missing_ts in missing_timestamps:\n",
    "                source_row = None\n",
    "                \n",
    "                # Determine if this is after last available (backward fill) or before (forward fill)\n",
    "                if missing_ts > last_available_ts:\n",
    "                    # BACKWARD FILL: search backward\n",
    "                    search_ts = missing_ts - timedelta(seconds=resolution_seconds)\n",
    "                    while search_ts >= market_start:\n",
    "                        if search_ts in day_data_indexed.index:\n",
    "                            source_row = day_data_indexed.loc[search_ts]\n",
    "                            break\n",
    "                        search_ts -= timedelta(seconds=resolution_seconds)\n",
    "                else:\n",
    "                    # FORWARD FILL: search forward\n",
    "                    search_ts = missing_ts + timedelta(seconds=resolution_seconds)\n",
    "                    while search_ts <= market_end:\n",
    "                        if search_ts in day_data_indexed.index:\n",
    "                            source_row = day_data_indexed.loc[search_ts]\n",
    "                            break\n",
    "                        search_ts += timedelta(seconds=resolution_seconds)\n",
    "                \n",
    "                # Create new row if source found\n",
    "                if source_row is not None:\n",
    "                    new_row = {\n",
    "                        'Datetime': missing_ts,\n",
    "                        'Open': source_row['Open'],\n",
    "                        'High': source_row['High'],\n",
    "                        'Low': source_row['Low'],\n",
    "                        'Close': source_row['Close'],\n",
    "                        'Volume': 0\n",
    "                    }\n",
    "                    new_rows.append(new_row)\n",
    "                    filled_timestamps.append(missing_ts.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "        # Add new rows and save\n",
    "        if new_rows:\n",
    "            df_new = pd.DataFrame(new_rows)\n",
    "            df = pd.concat([df.drop(columns=['Date']), df_new], ignore_index=True)\n",
    "            df = df.sort_values('Datetime').reset_index(drop=True)\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            new_count = len(df)\n",
    "            candles_filled = new_count - original_count\n",
    "            stocks_processed += 1\n",
    "            total_candles_filled += candles_filled\n",
    "            \n",
    "            fill_summary.append({\n",
    "                'stock': stock_name,\n",
    "                'filled': candles_filled,\n",
    "                'before': original_count,\n",
    "                'after': new_count,\n",
    "                'timestamps': filled_timestamps[:5]  # First 5\n",
    "            })\n",
    "            \n",
    "            print(f\"✓ Filled {candles_filled} candles ({original_count:,} → {new_count:,})\")\n",
    "        else:\n",
    "            print(\"✓ No missing candles\")\n",
    "            df = df.drop(columns=['Date'])\n",
    "    \n",
    "    # Print final summary\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{'FILL SUMMARY':^100}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    print(f\"Total stocks: {total_stocks}\")\n",
    "    print(f\"Stocks with filled candles: {stocks_processed}\")\n",
    "    print(f\"Total candles filled: {total_candles_filled:,}\")\n",
    "    \n",
    "    if fill_summary:\n",
    "        print(f\"\\n{'Stock':<20} {'Filled':<10} {'Before':<12} {'After':<12} {'Sample Timestamps'}\")\n",
    "        print(f\"{'-'*100}\")\n",
    "        \n",
    "        for item in sorted(fill_summary, key=lambda x: x['filled'], reverse=True):\n",
    "            timestamps_str = ', '.join(item['timestamps'][:3])\n",
    "            more = f\" ... +{len(item['timestamps'])-3}\" if len(item['timestamps']) > 3 else \"\"\n",
    "            print(f\"{item['stock']:<20} {item['filled']:<10} {item['before']:<12,} {item['after']:<12,} {timestamps_str}{more}\")\n",
    "    \n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    return fill_summary\n",
    "\n",
    "\n",
    "# ==================== EXECUTE ====================\n",
    "\n",
    "resolution = \"5S\"\n",
    "data_folder = r\"D:\\Programming\\Download_Backtest_Deploy_data\\1__Download\\1__Download_data_Fyers_via_API\\storage_Fyers_5S\"\n",
    "\n",
    "# Date range (not used for finding missing candles, just for reference)\n",
    "summary = fill_missing_candles(\n",
    "    resolution=resolution,\n",
    "    data_folder=data_folder,\n",
    "    date_range_start=\"2025-01-01\",\n",
    "    date_range_end=\"2025-09-30\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
