{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_row_data = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "# Function to remove integer values between \"~m~\" and \"~m~\"\n",
    "def remove_integers_from_payload(indicator_row_data):\n",
    "    pattern = re.compile(r'~m~\\d+~m~')\n",
    "    item = pattern.sub('', indicator_row_data)\n",
    "    return item\n",
    "\n",
    "# Apply the function to the data\n",
    "cleaned_data = remove_integers_from_payload(indicator_row_data)\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def convert_payload_to_dict(payload):\n",
    "    # Extract multiple JSON objects using regex\n",
    "    json_objects = re.findall(r'\\{.*?\\}', payload)\n",
    "    \n",
    "    parsed_objects = []\n",
    "    for obj in json_objects:\n",
    "        try:\n",
    "            parsed_objects.append(json.loads(obj))  # Convert each JSON object to a dictionary\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Skipping invalid JSON: {e}\")\n",
    "            # print(obj)\n",
    "            # print(type(obj))\n",
    "    \n",
    "    return parsed_objects\n",
    "\n",
    "# Example usage:\n",
    "converted_data = convert_payload_to_dict(cleaned_data)\n",
    "converted_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "\n",
    "filtered_sublist = [item for item in converted_data if 'i' in item.keys() or 'v' in item.keys()]\n",
    "filtered_data.append(filtered_sublist)\n",
    "\n",
    "converted_data = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_converted_data = []\n",
    "\n",
    "for sublist in converted_data:\n",
    "\n",
    "    unique_lengths = set()\n",
    "    for item in sublist:\n",
    "        print(item)\n",
    "        unique_lengths.add(len(item['v']))\n",
    "\n",
    "    unique_lengths = list(unique_lengths)\n",
    "    unique_lengths.sort()\n",
    "\n",
    "    # print(unique_lengths)\n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    length_dict = {}\n",
    "    for item in sublist:\n",
    "        length = len(item['v'])\n",
    "        if length not in length_dict:\n",
    "            length_dict[length] = []\n",
    "        length_dict[length].append(item)\n",
    "\n",
    "    # print(length_dict)\n",
    "    \n",
    "    for length, items in length_dict.items():\n",
    "        split_converted_data.append(items)\n",
    "\n",
    "# split_converted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for a in range(0, len(split_converted_data)):\n",
    "\n",
    "    qw = 'df' + str(a)\n",
    "\n",
    "    df_list.append(qw)\n",
    "\n",
    "for i in range(0, len(split_converted_data)):\n",
    "\n",
    "    # List of dictionaries\n",
    "    data_list = split_converted_data[i]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    # Expand the 'v' column into separate columns\n",
    "    df_expanded = pd.DataFrame(df['v'].tolist(), index=df['i'])\n",
    "\n",
    "    length_list = ['timestamp']\n",
    "\n",
    "    for q in range(0, len(split_converted_data[i][0]['v'])):\n",
    "\n",
    "        if q != 0:\n",
    "            length_list.append(str(q))\n",
    "\n",
    "    print(length_list)\n",
    "\n",
    "    # Rename columns\n",
    "    df_expanded.columns = length_list\n",
    "\n",
    "    df_expanded['timestamp'] = pd.to_datetime(df_expanded['timestamp'], unit='s', utc=True)\n",
    "    # df_expanded['timestamp'] = df_expanded['timestamp'].dt.tz_convert('Asia/Kolkata')\n",
    "    df_expanded['timestamp'] = df_expanded['timestamp'].dt.tz_localize(None)\n",
    "    df_expanded.rename(columns={'timestamp': 'datetime'}, inplace=True)\n",
    "\n",
    "    # Print the updated DataFrame\n",
    "    df_expanded = df_expanded.reset_index(drop=True)\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    df_list[i] = df_expanded\n",
    "\n",
    "    # Print the DataFrame\n",
    "    # qw = 'df' + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_remove = ['2', '4', '6', '8']\n",
    "# df = df.drop(columns=columns_to_remove)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'1': 'rising_', '2': 'falling_', '3': 'c_', '4': 'hi_', '5': 'lo_', \n",
    "                    '6': 'c1_', '7': 'anchoredHi_', '8': 'anchoredLo_', '9': 'h1_', '10': 'l1_', \n",
    "                    '11': 'o_', '12': 'doji_', '13': 'breakingHigher_', '14': 'breakingLower_', '15': 'resetHiAnchor_', \n",
    "                    '16': 'resetLoAnchor_', '17': 'VWAP', '18': 'Anchor_Hi', '19': 'Anchor_Lo', '20': 'anchoredMean'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    1.0: True, 11.0: True, 21.0: True, 31.0: True, 41.0: True, 51.0: True, 61.0: True,\n",
    "    2.0: False, 12.0: False, 22.0: False, 32.0: False, 42.0: False, 52.0: False, 62.0: False\n",
    "}\n",
    "\n",
    "columns_to_replace = ['rising_', 'falling_', 'doji_', 'breakingHigher_', 'breakingLower_', 'resetHiAnchor_', 'resetLoAnchor_']\n",
    "\n",
    "df[columns_to_replace] = df[columns_to_replace].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = input('Enter the stock name: ')\n",
    "df.to_csv(f'{stock_name}_AutoHI_Lo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
