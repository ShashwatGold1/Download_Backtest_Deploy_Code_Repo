{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Show All rows & columns -----------------------------\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c895753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- play_sound -----------------------------\n",
    "\n",
    "# import winsound\n",
    "\n",
    "# def play_sound(sound, Symbol_error, error_true):\n",
    "\n",
    "#     # Alert_01, Alert_02, Atma_rama_Alarm\n",
    "#     winsound.PlaySound(r\"D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\{}.wav\".format(sound), winsound.SND_FILENAME | winsound.SND_ASYNC)\n",
    "#     print(f\"\\033[1;31m{Symbol_error}\\033[0m\")\n",
    "        \n",
    "#     if error_true == \"error\":\n",
    "#         raise Exception(f\"\\033[1;31m{Symbol_error}\\033[0m\")\n",
    "\n",
    "# play_sound(\"Atma_rama_Alarm\", \"Symbol error\", \"error\")     # Alert_01, Alert_02, Atma_rama_Alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17089fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- ZeroLossMarketFeed Raw code \"Cell: 1\" -----------------------------\n",
    "\n",
    "# # Enable nested event loops for Jupyter\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# import asyncio\n",
    "# import ast\n",
    "# from dhanhq import dhanhq, DhanContext, MarketFeed\n",
    "# import functions as f\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from collections import deque\n",
    "# import time\n",
    "# import threading\n",
    "\n",
    "# class ZeroLossMarketFeed:\n",
    "#     def __init__(self, dhan_context, instruments, max_instruments_per_conn=50):\n",
    "#         self.dhan_context = dhan_context\n",
    "#         self.max_instruments_per_conn = max_instruments_per_conn\n",
    "#         self.tick_buffer = deque(maxlen=100000)  # Large buffer\n",
    "#         self.is_running = False\n",
    "#         self.connections = []\n",
    "        \n",
    "#         # Split instruments into batches\n",
    "#         self.instrument_batches = self._split_instruments(instruments)\n",
    "        \n",
    "#     def _split_instruments(self, instruments):\n",
    "#         \"\"\"Split instruments into batches of max_instruments_per_conn\"\"\"\n",
    "#         batches = []\n",
    "#         for i in range(0, len(instruments), self.max_instruments_per_conn):\n",
    "#             batch = instruments[i:i + self.max_instruments_per_conn]\n",
    "#             batches.append(batch)\n",
    "#         return batches\n",
    "    \n",
    "#     async def _handle_connection(self, instruments_batch, batch_id):\n",
    "#         \"\"\"Handle a single connection for a batch of instruments\"\"\"\n",
    "#         while self.is_running:\n",
    "#             try:\n",
    "#                 print(f\"Starting connection {batch_id} with {len(instruments_batch)} instruments\")\n",
    "                \n",
    "#                 # Create connection\n",
    "#                 feed = MarketFeed(self.dhan_context, instruments_batch, \"v2\")\n",
    "#                 await feed.connect()\n",
    "                \n",
    "#                 # Continuous data reception\n",
    "#                 while self.is_running:\n",
    "#                     try:\n",
    "#                         response = await feed.get_instrument_data()\n",
    "#                         if response:\n",
    "#                             # Immediately buffer the tick\n",
    "#                             self.tick_buffer.append({\n",
    "#                                 'timestamp': time.time(),\n",
    "#                                 'batch_id': batch_id,\n",
    "#                                 'data': response\n",
    "#                             })\n",
    "                            \n",
    "#                             # Process tick immediately (non-blocking)\n",
    "#                             self._process_tick_nonblocking(response)\n",
    "                            \n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Data reception error in batch {batch_id}: {e}\")\n",
    "#                         await asyncio.sleep(0.1)\n",
    "#                         break\n",
    "                        \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Connection error in batch {batch_id}: {e}\", \"\\tCheck Internet connection\")\n",
    "#                 await asyncio.sleep(1)  # Wait before reconnect\n",
    "    \n",
    "#     def _process_tick_nonblocking(self, tick_data):\n",
    "#         \"\"\"Process tick data without blocking the main loop\"\"\"\n",
    "#         try:\n",
    "#             # Your strategy logic here - keep it fast!\n",
    "#             # Example: Just print security_id and LTP\n",
    "#             if isinstance(tick_data, dict):\n",
    "#                 print(tick_data)\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Tick processing error: {e}\")\n",
    "    \n",
    "#     async def start_all_connections(self):\n",
    "#         \"\"\"Start all connections concurrently\"\"\"\n",
    "#         self.is_running = True\n",
    "        \n",
    "#         # Create tasks for each batch\n",
    "#         tasks = []\n",
    "#         for i, batch in enumerate(self.instrument_batches):\n",
    "#             task = asyncio.create_task(\n",
    "#                 self._handle_connection(batch, f\"batch_{i}\")\n",
    "#             )\n",
    "#             tasks.append(task)\n",
    "        \n",
    "#         print(f\"Starting {len(tasks)} connections...\")\n",
    "        \n",
    "#         # Run all connections concurrently\n",
    "#         try:\n",
    "#             await asyncio.gather(*tasks)\n",
    "#         except KeyboardInterrupt:\n",
    "#             print(\"Stopping all connections...\")\n",
    "#             self.is_running = False\n",
    "            \n",
    "#     def stop(self):\n",
    "#         \"\"\"Stop all connections\"\"\"\n",
    "#         self.is_running = False\n",
    "        \n",
    "#     def get_buffer_stats(self):\n",
    "#         \"\"\"Get buffer statistics\"\"\"\n",
    "#         return {\n",
    "#             'buffer_size': len(self.tick_buffer),\n",
    "#             'max_buffer': self.tick_buffer.maxlen,\n",
    "#             'buffer_usage': f\"{len(self.tick_buffer)/self.tick_buffer.maxlen*100:.1f}%\"\n",
    "#         }\n",
    "\n",
    "# # Your existing setup code\n",
    "# client_id = str(ast.literal_eval(f.get_line(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\database.txt', 3).strip())['client_id'])\n",
    "# access_token = str(ast.literal_eval(f.get_line(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\database.txt', 4).strip())['access_token'])\n",
    "\n",
    "# dhan_context = DhanContext(client_id, access_token)\n",
    "# dhan = dhanhq(dhan_context)\n",
    "\n",
    "# # Load and filter your option chain data\n",
    "# option_chain_df = pd.read_csv(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\Option_Chain_with_Security_id.csv')\n",
    "\n",
    "# def get_prices_under_1000(df):\n",
    "#     first_ce_idx = df[df['ce_last_price'] >= 800].index.max()\n",
    "#     first_pe_idx = df[df['pe_last_price'] >= 800].index.min()\n",
    "#     filtered_df = df[first_ce_idx:first_pe_idx].reset_index(drop=True)\n",
    "    \n",
    "#     ce_cols = ['security_id_CE', 'ce_iv', 'ce_volume', 'ce_oi', 'ce_last_price']\n",
    "#     pe_cols = ['pe_last_price', 'pe_iv', 'pe_oi', 'pe_volume', 'security_id_PE']\n",
    "    \n",
    "#     filtered_df.loc[filtered_df['ce_last_price'] < 10, ce_cols] = 0.0\n",
    "#     filtered_df.loc[filtered_df['pe_last_price'] < 10, pe_cols] = 0.0\n",
    "    \n",
    "#     return filtered_df\n",
    "\n",
    "# def create_instruments_from_df(df):\n",
    "#     instruments = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         if pd.notna(row['security_id_CE']) and row['security_id_CE'] != 0.0:\n",
    "#             instruments.append((MarketFeed.NSE_FNO, str(int(row['security_id_CE'])), MarketFeed.Ticker))\n",
    "#         if pd.notna(row['security_id_PE']) and row['security_id_PE'] != 0.0:\n",
    "#             instruments.append((MarketFeed.NSE_FNO, str(int(row['security_id_PE'])), MarketFeed.Ticker))\n",
    "#     return instruments\n",
    "\n",
    "# # Setup instruments\n",
    "# filtered_df = get_prices_under_1000(option_chain_df)\n",
    "# instruments = create_instruments_from_df(filtered_df)\n",
    "# instruments = instruments[:1]\n",
    "\n",
    "# print(f\"Total instruments: {len(instruments)}\")\n",
    "\n",
    "# # MAIN EXECUTION\n",
    "# async def main():\n",
    "#     # Create zero-loss feed with max 40 instruments per connection (safer than 50)\n",
    "#     feed_manager = ZeroLossMarketFeed(dhan_context, instruments, max_instruments_per_conn=40)\n",
    "    \n",
    "#     try:\n",
    "#         # Start all connections\n",
    "#         await feed_manager.start_all_connections()\n",
    "        \n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"Stopping feed...\")\n",
    "#         feed_manager.stop()\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Feed error: {e}\")\n",
    "#         feed_manager.stop()\n",
    "\n",
    "# # Run the async main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"Feed stopped by user\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fatal error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- ZeroLossMarketFeed Raw code \"Cell: 2\" -----------------------------\n",
    "\n",
    "# # Enable nested event loops for Jupyter\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# import asyncio\n",
    "# import ast\n",
    "# from dhanhq import dhanhq, DhanContext, MarketFeed\n",
    "# import functions as f\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from collections import deque\n",
    "# import time\n",
    "# import threading\n",
    "\n",
    "# class ZeroLossMarketFeed:\n",
    "#     def __init__(self, dhan_context, instruments, max_instruments_per_conn=50):\n",
    "#         self.dhan_context = dhan_context\n",
    "#         self.max_instruments_per_conn = max_instruments_per_conn\n",
    "#         self.tick_buffer = deque(maxlen=100000)  # Large buffer\n",
    "#         self.is_running = False\n",
    "#         self.connections = []\n",
    "        \n",
    "#         # Split instruments into batches\n",
    "#         self.instrument_batches = self._split_instruments(instruments)\n",
    "        \n",
    "#     def _split_instruments(self, instruments):\n",
    "#         \"\"\"Split instruments into batches of max_instruments_per_conn\"\"\"\n",
    "#         batches = []\n",
    "#         for i in range(0, len(instruments), self.max_instruments_per_conn):\n",
    "#             batch = instruments[i:i + self.max_instruments_per_conn]\n",
    "#             batches.append(batch)\n",
    "#         return batches\n",
    "    \n",
    "#     async def _handle_connection(self, instruments_batch, batch_id):\n",
    "#         \"\"\"Handle a single connection for a batch of instruments\"\"\"\n",
    "#         while self.is_running:\n",
    "#             try:\n",
    "#                 print(f\"Starting connection {batch_id} with {len(instruments_batch)} instruments\")\n",
    "                \n",
    "#                 # Create connection\n",
    "#                 feed = MarketFeed(self.dhan_context, instruments_batch, \"v2\")\n",
    "#                 await feed.connect()\n",
    "                \n",
    "#                 # Continuous data reception\n",
    "#                 while self.is_running:\n",
    "#                     try:\n",
    "#                         response = await feed.get_instrument_data()\n",
    "#                         if response:\n",
    "#                             # Immediately buffer the tick\n",
    "#                             self.tick_buffer.append({\n",
    "#                                 'timestamp': time.time(),\n",
    "#                                 'batch_id': batch_id,\n",
    "#                                 'data': response\n",
    "#                             })\n",
    "                            \n",
    "#                             # Process tick immediately (non-blocking)\n",
    "#                             self._process_tick_nonblocking(response)\n",
    "                            \n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Data reception error in batch {batch_id}: {e}\")\n",
    "#                         await asyncio.sleep(0.1)\n",
    "#                         break\n",
    "                        \n",
    "#             except Exception as e:\n",
    "#                 print(f\"Connection error in batch {batch_id}: {e}\", \"\\tCheck Internet connection\")\n",
    "#                 await asyncio.sleep(1)  # Wait before reconnect\n",
    "    \n",
    "#     def _process_tick_nonblocking(self, tick_data):\n",
    "#         \"\"\"Process tick data without blocking the main loop\"\"\"\n",
    "#         try:\n",
    "#             # Your strategy logic here - keep it fast!\n",
    "#             # Example: Just print security_id and LTP\n",
    "#             if isinstance(tick_data, dict):\n",
    "#                 print(tick_data)\n",
    "                \n",
    "#         except Exception as e:\n",
    "#             print(f\"Tick processing error: {e}\")\n",
    "    \n",
    "#     async def start_all_connections(self):\n",
    "#         \"\"\"Start all connections concurrently\"\"\"\n",
    "#         self.is_running = True\n",
    "        \n",
    "#         # Create tasks for each batch\n",
    "#         tasks = []\n",
    "#         for i, batch in enumerate(self.instrument_batches):\n",
    "#             task = asyncio.create_task(\n",
    "#                 self._handle_connection(batch, f\"batch_{i}\")\n",
    "#             )\n",
    "#             tasks.append(task)\n",
    "        \n",
    "#         print(f\"Starting {len(tasks)} connections...\")\n",
    "        \n",
    "#         # Run all connections concurrently\n",
    "#         try:\n",
    "#             await asyncio.gather(*tasks)\n",
    "#         except KeyboardInterrupt:\n",
    "#             print(\"Stopping all connections...\")\n",
    "#             self.is_running = False\n",
    "            \n",
    "#     def stop(self):\n",
    "#         \"\"\"Stop all connections\"\"\"\n",
    "#         self.is_running = False\n",
    "        \n",
    "#     def get_buffer_stats(self):\n",
    "#         \"\"\"Get buffer statistics\"\"\"\n",
    "#         return {\n",
    "#             'buffer_size': len(self.tick_buffer),\n",
    "#             'max_buffer': self.tick_buffer.maxlen,\n",
    "#             'buffer_usage': f\"{len(self.tick_buffer)/self.tick_buffer.maxlen*100:.1f}%\"\n",
    "#         }\n",
    "\n",
    "# # Your existing setup code\n",
    "# client_id = str(ast.literal_eval(f.get_line(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\database.txt', 3).strip())['client_id'])\n",
    "# access_token = str(ast.literal_eval(f.get_line(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\database.txt', 4).strip())['access_token'])\n",
    "\n",
    "# dhan_context = DhanContext(client_id, access_token)\n",
    "# dhan = dhanhq(dhan_context)\n",
    "\n",
    "# # Load and filter your option chain data\n",
    "# option_chain_df = pd.read_csv(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\Option_Chain_with_Security_id.csv')\n",
    "\n",
    "# def get_prices_under_1000(df):\n",
    "#     first_ce_idx = df[df['ce_last_price'] >= 800].index.max()\n",
    "#     first_pe_idx = df[df['pe_last_price'] >= 800].index.min()\n",
    "#     filtered_df = df[first_ce_idx:first_pe_idx].reset_index(drop=True)\n",
    "    \n",
    "#     ce_cols = ['security_id_CE', 'ce_iv', 'ce_volume', 'ce_oi', 'ce_last_price']\n",
    "#     pe_cols = ['pe_last_price', 'pe_iv', 'pe_oi', 'pe_volume', 'security_id_PE']\n",
    "    \n",
    "#     filtered_df.loc[filtered_df['ce_last_price'] < 10, ce_cols] = 0.0\n",
    "#     filtered_df.loc[filtered_df['pe_last_price'] < 10, pe_cols] = 0.0\n",
    "    \n",
    "#     return filtered_df\n",
    "\n",
    "# def create_instruments_from_df(df):\n",
    "#     instruments = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         if pd.notna(row['security_id_CE']) and row['security_id_CE'] != 0.0:\n",
    "#             instruments.append((MarketFeed.NSE_FNO, str(int(row['security_id_CE'])), MarketFeed.Ticker))\n",
    "#         if pd.notna(row['security_id_PE']) and row['security_id_PE'] != 0.0:\n",
    "#             instruments.append((MarketFeed.NSE_FNO, str(int(row['security_id_PE'])), MarketFeed.Ticker))\n",
    "#     return instruments\n",
    "\n",
    "# # Setup instruments\n",
    "# filtered_df = get_prices_under_1000(option_chain_df)\n",
    "# instruments = create_instruments_from_df(filtered_df)\n",
    "# # instruments = instruments[26:]\n",
    "# # instruments = instruments[:1]\n",
    "# instruments\n",
    "\n",
    "# print(f\"Total instruments: {len(instruments)}\")\n",
    "\n",
    "# # MAIN EXECUTION\n",
    "# async def main():\n",
    "#     # Create zero-loss feed with max 40 instruments per connection (safer than 50)\n",
    "#     feed_manager = ZeroLossMarketFeed(dhan_context, instruments, max_instruments_per_conn=40)\n",
    "    \n",
    "#     try:\n",
    "#         # Start all connections\n",
    "#         await feed_manager.start_all_connections()\n",
    "        \n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"Stopping feed...\")\n",
    "#         feed_manager.stop()\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Feed error: {e}\")\n",
    "#         feed_manager.stop()\n",
    "\n",
    "# # Run the async main function\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except KeyboardInterrupt:\n",
    "#         print(\"Feed stopped by user\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fatal error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1318afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Get 1 minute data with retry -----------------------------\n",
    "\n",
    "# import datetime\n",
    "# import pandas as pd\n",
    "# import time\n",
    "\n",
    "# def get_data(security_id):\n",
    "    \n",
    "#     today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#     for i in range(0, 3):\n",
    "#         # Get the latest minute chart data\n",
    "#         minute_chart = dhan.intraday_minute_data(\n",
    "#             security_id=security_id,\n",
    "#             exchange_segment=\"NSE_FNO\", \n",
    "#             instrument_type=\"OPTIDX\",\n",
    "#             from_date=today,\n",
    "#             to_date=today, \n",
    "#             interval=1\n",
    "#         )\n",
    "\n",
    "#         # Check if data is None or empty\n",
    "#         if not minute_chart[\"data\"]:\n",
    "#             print(\"Your API subscription has expired or API related error\", security_id)\n",
    "#             continue\n",
    "\n",
    "#         # Convert the data to a DataFrame\n",
    "#         minute_chart_df = pd.DataFrame(minute_chart[\"data\"])\n",
    "#         minute_chart_df['datetime'] = pd.to_datetime(minute_chart_df['timestamp'], unit='s') + pd.Timedelta(hours=5, minutes=30)\n",
    "#         minute_chart_df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "#         if minute_chart_df is not None:\n",
    "#             return minute_chart_df\n",
    "        \n",
    "#         time.sleep(0.14)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e72b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Get index of price filter effeciently -----------------------------\n",
    "\n",
    "# def fast_select_three_rows(df, price_col):\n",
    "#     # Convert to NumPy array for speed\n",
    "#     prices = df[price_col].values\n",
    "#     idx_below = (prices < 270).nonzero()[0]\n",
    "    \n",
    "#     if len(idx_below) == 0:\n",
    "#         raise ValueError(f\"No {price_col} < 270 found.\")\n",
    "    \n",
    "#     # Get index of max price below 270\n",
    "#     middle_pos = idx_below[prices[idx_below].argmax()]\n",
    "\n",
    "#     # Collect surrounding indices\n",
    "#     start = max(0, middle_pos - 1)\n",
    "#     end = min(len(df), middle_pos + 2)\n",
    "\n",
    "#     return df.iloc[start:end]\n",
    "\n",
    "# # Usage:\n",
    "# ce_selected = fast_select_three_rows(df, 'ce_last_price').copy()\n",
    "# ce_selected.drop(columns=['pe_last_price', 'pe_iv', 'pe_oi', 'pe_volume', 'security_id_PE'], inplace=True)\n",
    "\n",
    "# pe_selected = fast_select_three_rows(df, 'pe_last_price').copy()\n",
    "# pe_selected.drop(columns=['security_id_CE', 'ce_iv', 'ce_volume', 'ce_oi', 'ce_last_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Tick data count analysis for market feed \"Cell: 1\" -----------------------------\n",
    "\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import struct\n",
    "# from pathlib import Path\n",
    "# from datetime import datetime\n",
    "# from dhanhq import MarketFeed\n",
    "\n",
    "# class TickFileReader:\n",
    "#     \"\"\"Fast reader for tick files - supports parallel reading\"\"\"\n",
    "    \n",
    "#     RECORD_SIZE = 32\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def read_last_tick(filepath):\n",
    "#         \"\"\"Read only the last tick - ultra fast\"\"\"\n",
    "#         try:\n",
    "#             with open(filepath, 'rb') as f:\n",
    "#                 # Seek to last complete record\n",
    "#                 f.seek(-TickFileReader.RECORD_SIZE, 2)\n",
    "#                 data = f.read(TickFileReader.RECORD_SIZE)\n",
    "                \n",
    "#                 if len(data) == TickFileReader.RECORD_SIZE:\n",
    "#                     time_bytes, price, oi, volume = struct.unpack('8sddd', data)\n",
    "#                     ltt = time_bytes.rstrip(b'\\x00').decode('utf-8')\n",
    "#                     return {\n",
    "#                         'LTT': ltt,\n",
    "#                         'price': price,\n",
    "#                         'OI': oi,\n",
    "#                         'volume': volume\n",
    "#                     }\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Error reading last tick: {e}\")\n",
    "#         return None\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def read_full_file(filepath):\n",
    "#         \"\"\"Read entire file - returns all ticks\"\"\"\n",
    "#         ticks = []\n",
    "#         try:\n",
    "#             with open(filepath, 'rb') as f:\n",
    "#                 while True:\n",
    "#                     data = f.read(TickFileReader.RECORD_SIZE)\n",
    "#                     if len(data) != TickFileReader.RECORD_SIZE:\n",
    "#                         break\n",
    "                    \n",
    "#                     time_bytes, price, oi, volume = struct.unpack('8sddd', data)\n",
    "#                     ltt = time_bytes.rstrip(b'\\x00').decode('utf-8')\n",
    "                    \n",
    "#                     # Skip empty records\n",
    "#                     if ltt:\n",
    "#                         ticks.append({\n",
    "#                             'LTT': ltt,\n",
    "#                             'price': price,\n",
    "#                             'OI': oi,\n",
    "#                             'volume': volume\n",
    "#                         })\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Error reading full file: {e}\")\n",
    "        \n",
    "#         return ticks\n",
    "    \n",
    "# # PARALLEL READING FUNCTIONS\n",
    "# def read_latest_tick(security_id, data_path=r\"D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\"):\n",
    "#     \"\"\"Read latest tick for a security - ULTRA FAST\"\"\"\n",
    "#     today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "#     filepath = Path(data_path) / \"Tick_data\" / f\"market_data_{today_date}\" / f\"{security_id}.bin\"\n",
    "#     return TickFileReader.read_last_tick(filepath)\n",
    "\n",
    "# def read_all_ticks(security_id, data_path=r\"D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\"):\n",
    "#     \"\"\"Read all ticks for a security\"\"\"\n",
    "#     today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "#     filepath = Path(data_path) / \"Tick_data\" / f\"market_data_{today_date}\" / f\"{security_id}.bin\"\n",
    "#     return TickFileReader.read_full_file(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945df504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Tick data count analysis for market feed \"Cell: 2\" -----------------------------\n",
    "\n",
    "# market_feed_data = [{'type': 'Ticker Data', 'exchange_segment': 2, 'security_id': 50993, 'LTP': '366.35', 'LTT': '12:11:41'},\n",
    "#     {'type': 'Previous Close', 'exchange_segment': 2, 'security_id': 50993, 'prev_close': '226.85', 'prev_OI': 1236905968},\n",
    "#     {'type': 'Ticker Data', 'exchange_segment': 2, 'security_id': 50990, 'LTP': '37.40', 'LTT': '12:11:42'},\n",
    "#     {'type': 'Previous Close', 'exchange_segment': 2, 'security_id': 50990, 'prev_close': '113.90', 'prev_OI': 1251054434},\n",
    "#     {'type': 'Ticker Data', 'exchange_segment': 2, 'security_id': 50961, 'LTP': '822.50', 'LTT': '12:08:45'},\n",
    "#     {'type': 'Previous Close', 'exchange_segment': 2, 'security_id': 50961, 'prev_close': '622.35', 'prev_OI': 1198364928},\n",
    "#     {'type': 'Ticker Data', 'exchange_segment': 2, 'security_id': 51008, 'LTP': '136.75', 'LTT': '12:11:42'},\n",
    "#     {'type': 'Previous Close', 'exchange_segment': 2, 'security_id': 51008, 'prev_close': '302.45', 'prev_OI': 1234819168},\n",
    "#     {'type': 'Ticker Data', 'exchange_segment': 2, 'security_id': 50963, 'LTP': '771.05', 'LTT': '12:11:13'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Tick data count analysis for market feed \"Cell: 3\" -----------------------------\n",
    "\n",
    "# option_chain_df = pd.read_csv(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\data\\Option_Chain_with_Security_id.csv')\n",
    "\n",
    "# def get_prices_under_1000(df):\n",
    "#     \"\"\"Filter function exactly like original\"\"\"\n",
    "#     first_ce_idx = df[df['ce_last_price'] >= 800].index.max()\n",
    "#     first_pe_idx = df[df['pe_last_price'] >= 800].index.min()\n",
    "#     filtered_df = df[first_ce_idx:first_pe_idx].reset_index(drop=True)\n",
    "    \n",
    "#     ce_cols = ['security_id_CE', 'ce_iv', 'ce_volume', 'ce_oi', 'ce_last_price']\n",
    "#     pe_cols = ['pe_last_price', 'pe_iv', 'pe_oi', 'pe_volume', 'security_id_PE']\n",
    "    \n",
    "#     filtered_df.loc[filtered_df['ce_last_price'] < 10, ce_cols] = 0.0\n",
    "#     filtered_df.loc[filtered_df['pe_last_price'] < 10, pe_cols] = 0.0\n",
    "    \n",
    "#     return filtered_df\n",
    "\n",
    "# def create_instruments_from_df(df):\n",
    "#     \"\"\"Create instruments exactly like original\"\"\"\n",
    "#     instruments = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         if pd.notna(row['security_id_CE']) and row['security_id_CE'] != 0.0:\n",
    "#             instruments.append((MarketFeed.NSE_FNO, str(int(row['security_id_CE'])), MarketFeed.Ticker))\n",
    "#         if pd.notna(row['security_id_PE']) and row['security_id_PE'] != 0.0:\n",
    "#             instruments.append((MarketFeed.NSE_FNO, str(int(row['security_id_PE'])), MarketFeed.Ticker))\n",
    "#     return instruments\n",
    "\n",
    "# # Setup instruments\n",
    "# filtered_df = get_prices_under_1000(option_chain_df)\n",
    "# instruments = create_instruments_from_df(filtered_df)\n",
    "\n",
    "# # -----------------------------------------\n",
    "\n",
    "# from_where_to_read = \"raw_output\"  # \"raw_output\" \"from_file\"\n",
    "\n",
    "# if from_where_to_read == \"raw_output\":\n",
    "    \n",
    "#     market_feed_data_df = pd.DataFrame(market_feed_data)\n",
    "\n",
    "#     security_id_counts = market_feed_data_df['security_id'].value_counts()\n",
    "\n",
    "# if from_where_to_read == \"from_file\":\n",
    "\n",
    "#     # Initialize an empty list to store all ticks\n",
    "#     all_ticks = []\n",
    "\n",
    "#     # Iterate over all files in the directory\n",
    "#     for file_name in os.listdir(r'D:\\Programming\\Download_Backtest_Deploy_data\\5__Deploy\\Multi_deploy\\Tick_data\\market_data_2025-06-19'):\n",
    "#         if file_name.endswith(\".bin\"):\n",
    "#             # Extract the security_id from the file name\n",
    "#             security_id = file_name.split(\".\")[0]\n",
    "#             # Read all ticks for the security_id\n",
    "#             ticks = read_all_ticks(security_id)\n",
    "#             all_ticks.extend([int(security_id)] * int(len(ticks)))\n",
    "\n",
    "#     # Create a DataFrame from the ticks and calculate security_id_counts\n",
    "#     all_ticks_df = pd.DataFrame(all_ticks, columns=[\"security_id\"])\n",
    "#     security_id_counts = all_ticks_df['security_id'].value_counts()\n",
    "\n",
    "# # -----------------------------------------\n",
    "\n",
    "# # Create the count columns\n",
    "# filtered_df[\"counts_ce\"] = filtered_df[\"security_id_CE\"].map(security_id_counts).fillna(0).astype(int)\n",
    "# filtered_df[\"counts_pe\"] = filtered_df[\"security_id_PE\"].map(security_id_counts).fillna(0).astype(int)\n",
    "\n",
    "# # Reorder columns\n",
    "# cols = filtered_df.columns.tolist()\n",
    "\n",
    "# # Move ce count to first, pe count to last\n",
    "# cols.insert(0, cols.pop(cols.index(\"counts_ce\")))  # move to front\n",
    "# cols.append(cols.pop(cols.index(\"counts_pe\")))     # move to end\n",
    "\n",
    "# # Apply the new order\n",
    "# filtered_df = filtered_df[cols]\n",
    "\n",
    "# print(len(instruments))\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ee1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------- Check Internet Connection -----------------------------\n",
    "\n",
    "# from datetime import datetime, timedelta\n",
    "# import socket\n",
    "# from IPython.display import display, HTML, Javascript\n",
    "# import time\n",
    "\n",
    "# def update_element(s):\n",
    "#     display(HTML(\"\"\"<div><pre id=\"clock\" style='margin:0; padding:0;'></pre></div>\"\"\"))\n",
    "#     display(Javascript(f\"\"\"document.getElementById('clock').innerHTML = '{s}';\"\"\"))\n",
    "\n",
    "# def is_internet_available():\n",
    "\n",
    "#     starting_time = str(datetime.now())\n",
    "#     start_time = datetime.strptime(starting_time, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "#     time_elapsed = None\n",
    "\n",
    "#     while True:\n",
    "#         try:\n",
    "#             # Attempt to connect to Google's DNS server\n",
    "#             socket.create_connection((\"8.8.8.8\", 53), timeout=3)\n",
    "#             if time_elapsed is not None:\n",
    "#                 print(f\"Successfully connected to the internet after 0{time_elapsed}\")\n",
    "#             print(f\"Internet Connection: 'Available'\")\n",
    "#             return True\n",
    "#         except OSError:\n",
    "            \n",
    "#             current_time = datetime.now()\n",
    "#             time_elapsed = str(current_time - start_time).split('.')[0]\n",
    "\n",
    "#             update_element(f\"Internet connection lost, retrying... Time Elapsed: 0{time_elapsed}\")\n",
    "\n",
    "#             time.sleep(1)\n",
    "\n",
    "# is_internet_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356aebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_status_server.py\n",
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "\n",
    "class StatusHandler(BaseHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        self.send_response(200)\n",
    "        self.end_headers()\n",
    "        self.wfile.write(b\"PC is online\")\n",
    "\n",
    "def run():\n",
    "    server_address = ('0.0.0.0', 8989)\n",
    "    httpd = HTTPServer(server_address, StatusHandler)\n",
    "    print(\"PC status server running on port 8989\")\n",
    "    httpd.serve_forever()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88178e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobile_checker.py\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "\n",
    "PC_IP = \"192.168.X.X\"  # Replace with PC's local IP (for hotspot)\n",
    "PC_PORT = 8989\n",
    "\n",
    "def play_alarm():\n",
    "    os.system('termux-media-player play /sdcard/alarm.mp3')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        r = requests.get(f\"http://{PC_IP}:{PC_PORT}\", timeout=3)\n",
    "        print(\"PC is online:\", r.text)\n",
    "    except:\n",
    "        print(\"PC is unreachable — triggering alarm\")\n",
    "        play_alarm()\n",
    "        break  # Optional: break or keep trying\n",
    "    time.sleep(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
